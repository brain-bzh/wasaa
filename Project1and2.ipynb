{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f630f87b",
   "metadata": {},
   "source": [
    "WASAA 2023 - Ressources for projects 1 and 2 \n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aea375",
   "metadata": {},
   "source": [
    "These ressources are common to the two projects : \n",
    "- \"Classification of patients with Autism Spectrum Disorder using spontaneous brain activity\" \n",
    "- \"Networks in brain pathologies using spontaneous brain activity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bd9387",
   "metadata": {},
   "source": [
    "There are two datasets on which you can do experiments : ABIDE and ADHD. \n",
    "\n",
    "ADHD is probably easier to work with as there are only 40 subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e469f9c",
   "metadata": {},
   "source": [
    "ADHD dataset\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf430a",
   "metadata": {},
   "source": [
    "To download the ADHD dataset, use the [nilearn fetcher]([documentation](https://nilearn.github.io/stable/modules/generated/nilearn.datasets.fetch_abide_pcp.html#nilearn.datasets.fetch_abide_pcp)) as done in the next cell. A few comments : \n",
    "- The code first checks if the dataset has been downloaded or not, and will not download if the files are detected. \n",
    "- Here I download only two subjects so that it's not too long, but there are 40 subjects in total \n",
    "- the `data_dir` argument can be changed. There are only two relevant options : using the network drive (if you leave `data_dir = './'`) or using the drive of the local machine you are using `data_dir = '/users/local/'`. Local drive will be faster and you have a lot more space, but you'll have to download again if you switch to another machine\n",
    "- You can also check the official page of the dataset [here](http://fcon_1000.projects.nitrc.org/indi/adhd200/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "839086c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_adhd\n",
    "\n",
    "n_subjects = 2\n",
    "dataset = fetch_adhd(n_subjects=n_subjects,data_dir = './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf72285b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['func', 'confounds', 'phenotypic', 'description'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e76a52",
   "metadata": {},
   "source": [
    "'func', 'confounds' will be lists of files, each element in the list correspond to a subject. 'func' is the functional MRI data file, and 'confounds' is a text file with an array corresponding to nuisance variables that need to be regressed out, as explained in [this tutorial](https://nilearn.github.io/stable/auto_examples/03_connectivity/plot_signal_extraction.html#sphx-glr-auto-examples-03-connectivity-plot-signal-extraction-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6516dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADHD 200\n",
      "\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Part of the 1000 Functional Connectome Project. Phenotypic\n",
      "information includes: diagnostic status, dimensional ADHD symptom measures,\n",
      "age, sex, intelligence quotient (IQ) and lifetime medication status.\n",
      "Preliminary quality control assessments (usable vs. questionable) based upon\n",
      "visual timeseries inspection are included for all resting state fMRI scans.\n",
      "\n",
      "Includes preprocessed data from 40 participants.\n",
      "\n",
      "Project was coordinated by Michael P. Milham.\n",
      "\n",
      "Content\n",
      "-------\n",
      "    :'func': Nifti images of the resting-state data\n",
      "    :'phenotypic': Explanations of preprocessing steps\n",
      "    :'confounds': CSV files containing the nuisance variables\n",
      "\n",
      "References\n",
      "----------\n",
      "For more information about this dataset's structure:\n",
      "http://fcon_1000.projects.nitrc.org/indi/adhd200/index.html\n",
      "\n",
      "Licence: usage is unrestricted for non-commercial research purposes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "020b9dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./adhd/data/0010042/0010042_regressors.csv',\n",
       " './adhd/data/0010064/0010064_regressors.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['confounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7ae4418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz',\n",
       " './adhd/data/0010064/0010064_rest_tshift_RPI_voreg_mni.nii.gz']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['func']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6a0e36",
   "metadata": {},
   "source": [
    "And finally 'phenotype' gives other information on the subjects. For example here is the phenotypic info for the first subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "937d2a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'\"21\"', 10042, b'\"rest_1\"', 0.0559, 0, 0.2365, 0.0922, 0., 2.2915, 1.0089, b'\"NYU\"', b'NA', b'\"data_set\"', 10.65, b'\"M\"', b'\"0.91\"', b'NA', b'108', b'100', b'115', b'2', 0, 1, b'NA', b'NA', b'NA', b'\"\"', b'\"\"', b'\"\"', b'NA', b'NA', b'NA', b'NA', b'NA', b'NA', b'NA', b'NA', b'NA', b'NA', b'NA', b'59', b'56', b'65', b'NA', b'\"pass\"', b'\"\"', b'\"pass\"', b'\"\"', b'\"\"', b'\"\"', b'NA', b'NA', b'NA', b'NA', b'NA', b'NA', b'\"pass\"', b'NA', b'NA', b'NA', b'NA', b'NA', b'NA', b'\"\"', b'\"\"')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['phenotypic'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6703f",
   "metadata": {},
   "source": [
    "Here are the keys to interpret what these values correspond to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67149ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('f0', 'S4'), ('Subject', '<i8'), ('RestScan', 'S8'), ('MeanFD', '<f8'), ('NumFD_greater_than_020', '<i8'), ('rootMeanSquareFD', '<f8'), ('FDquartiletop14thFD', '<f8'), ('PercentFD_greater_than_020', '<f8'), ('MeanDVARS', '<f8'), ('MeanFD_Jenkinson', '<f8'), ('site', 'S12'), ('sibling_id', 'S7'), ('data_set', 'S10'), ('age', '<f8'), ('sex', 'S3'), ('handedness', 'S6'), ('full_2_iq', 'S3'), ('full_4_iq', 'S3'), ('viq', 'S3'), ('piq', 'S3'), ('iq_measure', 'S2'), ('tdc', '<i8'), ('adhd', '<i8'), ('adhd_inattentive', 'S2'), ('adhd_combined', 'S2'), ('adhd_subthreshold', 'S2'), ('diagnosis_using_cdis', 'S12'), ('notes', 'S24'), ('sess_1_anat_2', 'S6'), ('oppositional', 'S2'), ('cog_inatt', 'S2'), ('hyperac', 'S2'), ('anxious_shy', 'S2'), ('perfectionism', 'S2'), ('social_problems', 'S2'), ('psychosomatic', 'S2'), ('conn_adhd', 'S2'), ('restless_impulsive', 'S2'), ('emot_lability', 'S2'), ('conn_gi_tot', 'S2'), ('dsm_iv_inatt', 'S2'), ('dsm_iv_h_i', 'S2'), ('dsm_iv_tot', 'S2'), ('study', 'S2'), ('sess_1_rest_1', 'S6'), ('sess_1_rest_1_eyes', 'S8'), ('sess_1_rest_2', 'S14'), ('sess_1_rest_2_eyes', 'S8'), ('sess_1_rest_3', 'S6'), ('sess_1_rest_3_eyes', 'S6'), ('sess_1_rest_4', 'S2'), ('sess_1_rest_4_eyes', 'S2'), ('sess_1_rest_5', 'S2'), ('sess_1_rest_5_eyes', 'S2'), ('sess_1_rest_6', 'S2'), ('sess_1_rest_6_eyes', 'S2'), ('sess_1_anat_1', 'S6'), ('sess_1_which_anat', 'S2'), ('sess_2_rest_1', 'S2'), ('sess_2_rest_1_eyes', 'S2'), ('sess_2_rest_2', 'S2'), ('sess_2_rest_2_eyes', 'S2'), ('sess_2_anat_1', 'S2'), ('defacing_ok', 'S5'), ('defacing_notes', 'S35')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['phenotypic'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93bb646",
   "metadata": {},
   "source": [
    "We are probably only interested in age, sex, handedness, iq_measure, tdc, adhd, adhd_innatentive, adhd_combined, adhd_subthreshold, diagnosis. You'll have to extract the corresponding columns from the phenotypic vectors of each subject. \n",
    "Other values correspond to specific steps in preprocessing but you can ignore them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718dfde1",
   "metadata": {},
   "source": [
    "The coding of some of the fields is described in [this file](http://fcon_1000.projects.nitrc.org/indi/adhd200/general/ADHD-200_PhenotypicKey.pdf)  (Key explaining the values used to code site, gender, handedness, diagnosis, ADHD measure, IQ measure, medication status and quality control in each sample's phenotypic.csv file.) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d13736",
   "metadata": {},
   "source": [
    "ABIDE dataset\n",
    "--\n",
    "Unfortunately the automatic fetching of the ABIDE data seems to not work currently (probably a S3 server is down or so)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b04145",
   "metadata": {},
   "source": [
    "Next steps\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77fd287",
   "metadata": {},
   "source": [
    "- Parcellate the data: use a masker to generate a time series on this parcellation. You may also use the confounds csv file to regress out confounds while masking \n",
    "- Estimate a functional connectivity matrix for each subject\n",
    "- Project 1 : extract the upper triangular values of this matrix as a vector (using [triu](https://numpy.org/doc/stable/reference/generated/numpy.triu.html)), and use supervised learning (e.g. KNN) to try to differentiate subjects based on phenotype (eg ADHD diagnosis or other variables)\n",
    "- Project 2 : Use the matrix to compute Graph metrics for each subject using the package bctpy (can be installed with pip), and try to relate those graph metrics with phenotype using simple statistics (regression, correlation). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a260c",
   "metadata": {},
   "source": [
    "Of course the project is left open for you to explore. Feel free to test other ideas as well, and check out papers that have been published with the same dataset. And feel free to reach out by email. \n",
    "\n",
    "Good luck ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('base': conda)",
   "language": "python",
   "name": "python36964bitbaseconda6c8d87063a18461ca77c51084a3826c5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
